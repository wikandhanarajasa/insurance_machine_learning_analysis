# -*- coding: utf-8 -*-
"""Project Sprint 11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1czCwTG5JJwNbuY1qsHHoOlnguGZP8y6t

# **Machine Learning for "Sure Tomorrow" Insurance**

## **Introduction**

Sure Tomorrow (not a real company) an innovative insurance company, is seeking to leverage machine learning to address several key business challenges. The company aims to enhance its marketing efforts, predict potential insurance claims, and estimate the size of claims for new clients. Additionally, safeguarding client data through effective anonymization methods is crucial to ensure privacy without compromising the quality of predictive models. This project focuses on evaluating the feasibility and effectiveness of machine learning solutions for these tasks.

### **Goals**

1. **Client Similarity Analysis**: Identify clients who match specific criteria to aid in targeted marketing. This involves finding clients with similar characteristics to enhance the efficiency of marketing campaigns.
   
2. **Claim Probability Prediction**: Predict whether a new client is likely to make an insurance claim. This will be assessed against a dummy model to determine if the machine learning model offers a significant improvement.

3. **Claim Amount Estimation**: Use linear regression to estimate the potential claim amount for new clients. This task will help in assessing the financial risk associated with new policies.

4. **Data Protection**: Implement data anonymization techniques to protect client information while preserving the effectiveness of the predictive models. The goal is to ensure that even if data is compromised, it remains unusable for malicious purposes.

### **Instructions**

1. **Data Loading and Preparation**: Begin by loading the dataset from `/datasets/insurance_us.csv`. Perform thorough data cleaning to address missing values, outliers, and any other anomalies.

2. **Task Implementation**: Complete each of the four tasks using machine learning techniques. For each task, answer the associated questions provided in the project template.

3. **Conclusion**: Summarize your findings and experiences from the project. Reflect on the effectiveness of your models and data protection measures.

4. **Code Utilization**: Utilize the initial code provided in the project template as a starting point. Some of this code will need to be completed to achieve the project goals.

### **Dataset Description**

The dataset is includes the following features:

- **Gender**: The gender of the insured individual.
- **Age**: The age of the insured individual.
- **Salary**: The salary of the insured individual.
- **Family Size**: The number of family members of the insured individual.

The target variable is the **Claim Amount**: The total amount of claims received by the insured individual over the past five years.

By addressing these tasks, you will help "Sure Tomorrow" improve their marketing strategies, better predict insurance claims, and manage client data securely.

## **Data Loadment and Exploratory**
"""

pip install scikit-learn --upgrade

import numpy as np
import pandas as pd

import seaborn as sns
import math
import sklearn.metrics

import sklearn.linear_model
import sklearn.metrics
import sklearn.neighbors
import sklearn.preprocessing
from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor
from sklearn.metrics import confusion_matrix, f1_score, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

from sklearn.model_selection import train_test_split

from IPython.display import display

"""### **Data Loadment**"""

df = pd.read_csv('/content/insurance_us.csv')

df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})

df.sample(5)

df.info()

# Change the age column data type from float to integer
df['age'] = df['age'].astype(int)

df.info()

# Checking statistical figures
df.describe()

# Checking for duplicate data
df.duplicated().sum()

"""153 duplicate data were found, to avoid redundant calculations, these 153 data can be deleted."""

df = df.drop_duplicates()

df.info()

df.duplicated().sum()

# Checking for empty values ‚Äã‚Äãin data
df.isnull().sum()

"""**Summary**

1. Based on descriptive statistics, it can be seen that there are no problems with the dataset.
2. There are 153 rows that are duplicated and have been dropped duplicated to avoid redundant results.

### **Exploratory Data Analysis**

Data analysis and exploration are carried out to create an overall picture (summary) of the data so that it is easy to understand.
"""

g = sns.pairplot(df, kind='hist')
g.fig.set_size_inches(12, 12)

df.corr()

"""**Summary**

1. Based on the results of analysis and exploratory data, it was concluded that age has a positive effect on receiving benefits.

## **Client Similarity Analysis**

In the ML programming language, it is important to develop a procedure that can determine *k-nearest neighbors* (objects) for a particular object based on the distance between objects. The methods that can be used are:

- Distance Between Vectors -> Euclidean Distance
- Distance Between Vectors -> Manhattan Distance

To accomplish this task, we can try several distance metrics.

*k-nearest neighbors* will be used to measure the closest distance for the nth object based on a certain distance metric. The amount of insurance claims received does not need to be taken into account in this task.

An implementation of the kNN algorithm is already available in Scikit-learn (check this [link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors).

Test the algorithm for four combinations of two cases
- Scaling
 - data is not scaled
 - data scaled with [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)
- Distance Metrics
 - Euclid
 - Manhattan
"""

feature_names = ['gender', 'age', 'income', 'family_members']

def get_knn(df, n, k, metric):

    nbrs = NearestNeighbors(n_neighbors=k, algorithm='brute', metric=metric).fit(df[feature_names])
    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)

    list_index = df.iloc[nbrs_indices[0]].index

    df_res = pd.concat([df.iloc[nbrs_indices[0]].reset_index(drop=True),
                        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance']).reset_index(drop=True)
        ], axis=1).set_index(list_index)

    return df_res

get_knn(df=df, n=10, k=5, metric='euclidean')

# Set data scale
feature_names = ['gender', 'age', 'income', 'family_members']

transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())

df_scaled = df.copy()
df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())

df_scaled.sample(5)

"""Now, let's get similar records for each existing combination"""

get_knn(df=df_scaled, n=10, k=5, metric='euclidean')

get_knn(df=df_scaled, n=10, k=5, metric='manhattan')

"""**Insight**

It can be seen between the two datasets that have not been scalarized and those that have not been scalarized tend to lead to the highest column values ‚Äã‚Äãsuch as the income column, while for data that has been scalarized it tends to be flatter.

There is no significant difference between the two.

## **Claim Probability Prediction**

With an insurance_benefits target of more than zero, we will evaluate whether the kNN classification model is a better approach than the *dummy* model.

Step:
- KNN based classifier and quality measurement with F1 metric for k=1..10 for original and scaled data. It will be interesting to see how k can affect the evaluation metrics, and whether scaling the data makes the results different. Use the kNN classification algorithm implementation available in Scikit-learn (check [this link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) or use your own.
- Random *dummy* model creation for this case. The model should return "1" with some probability. Let's test the model with four probability values: 0, the probability of paying any insurance benefit; 0.5; 1.

The probability of paying an insurance claim can be defined as

$$
P\{\text{insurance claims received}\}=\frac{\text{number of clients who received insurance claims}}{\text{total number of clients}}.
$$

The overall data separation is 70:30 for the proportion of *training* and *test set*.
"""

df.head()

# Calculate the target

df['insurance_benefits_received'] = (df['insurance_benefits'] > 0).astype(int)

df.head()

# check for class imbalance with value_counts()

df['insurance_benefits_received'].value_counts()

def dummy_model(probability, size=len(df)):
    rng = np.random.default_rng(seed=12)
    prediction = rng.binomial(n=1, p=probability, size=size)
    return prediction

def eval_classifier(y_true, y_pred, average=None):

    f1_score = sklearn.metrics.f1_score(y_true, y_pred, average=average)
    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    print(f'F1: {f1_score*100:.2f}')
    print(f'Accuracy: {acc* 100:.2f}%')
    print('Matriks Kesalahan')
    print(cm)

y_true = df['insurance_benefits_received']

# Model predictions with a dummy with a proportion of 90:10
print('Prediksi model dummy dengan proporsi 90:10')
y_pred_dummy = dummy_model(probability=0.1, size=len(df))
eval_classifier(y_true, y_pred_dummy, average='weighted')
print('------------------------------------------')

# Model predictions with a dummy with a 50:50 proportion
print('Prediksi model dummy dengan proporsi 50:50')
y_pred_dummy = dummy_model(probability=0.5, size=len(df))
eval_classifier(y_true, y_pred_dummy, average='weighted')
print('------------------------------------------')

# Model predictions with a dummy with a proportion of 70:30
print('Prediksi model dummy dengan proporsi 70:30')
y_pred_dummy = dummy_model(probability=0.3, size=len(df))
eval_classifier(y_true, y_pred_dummy, average='weighted')
print('------------------------------------------')

# Train Test Split
X = df[feature_names]
y = df['insurance_benefits_received']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)

# Scaling data
scaler = StandardScaler()
scaler.fit(X_train)

X_train = pd.DataFrame(scaler.transform(X_train), columns=feature_names)
X_train.head()

X_test = pd.DataFrame(scaler.transform(X_test), columns=feature_names)
X_test.head()

# Create a model using KNN

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

# Predict data Training
y_pred_train = knn.predict(X_train)
eval_classifier(y_train, y_pred_train, average='weighted')

# Predict data Testing
y_pred_test = knn.predict(X_test)
eval_classifier(y_test, y_pred_test, average='weighted')

"""**Summary**

1. The dummy model has a low level of accuracy and F1 score compared to kNN classification.
2. The level of accuracy and F1 score on the train and test datasets using the kNN approach has a relatively high value at more than 98%.

## **Claim Amount Estimation**

With `insurance_benefit` as the target, evaluate what the RMSE is for the Linear Regression model.

LR is used in this sub-project. RMSE check for original data and scaled data.

Show
- $X$ ‚Äî feature matrix, one row represents one case, each column is a feature, the first column consists of units
- $y$ ‚Äî target (vector)
- $\hat{y}$ ‚Äî target estimate (vector)
- $w$ ‚Äî vector weight

The matrix for linear regression can be formulated as

$$
y = Xw
$$

Training objective to find $w$ that will minimize the L2 distance (MSE) between $Xw$ and $y$:

$$
\min_w d_2(Xw, y) \quad \text{or} \quad \min_w \text{MSE}(Xw, y)
$$

It looks like there is an analytical solution to the above problem:

$$
w = (X^T X)^{-1}
$$

The above formula can be used to find the weight $w$ and the last one can be used to calculate the predicted value

$$
\hat{y} = X_{val}w
$$

The entire data into *training set* and *validation set* are separated by a proportion of 70:30. Use of the RMSE metric for model evaluation.
"""

class MyLinearRegression:

    def __init__(self):

        self.weights = None

    def fit(self, X, y):

        # menambahkan satuan
        X2 = np.append(np.ones([len(X), 1]), X, axis=1)
        self.weights = np.linalg.inv(X2.T @ X2) @ X2.T @ y

    def predict(self, X):

        # menambahkan satuan
        X2 = np.append(np.ones([len(X), 1]), X, axis=1)
        y_pred = X2 @ self.weights

        return y_pred

def eval_regressor(y_true, y_pred):

    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))
    print(f'RMSE: {rmse:.2f}')

    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))
    print(f'R2: {r2_score:.2f}')

X = df[['age', 'gender', 'income', 'family_members']].to_numpy()
y = df['insurance_benefits'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

lr = MyLinearRegression()

lr.fit(X_train, y_train)
print(lr.weights)

y_test_pred = lr.predict(X_test)
eval_regressor(y_test, y_test_pred)

"""**Summary**

1. Obtained an RMSE score of 0.36.
2. Obtained an R2 score of 0.66.

## **Data Protection**

The best way to blur the data is to multiply the numerical features (remember that these features can be seen in the matrix $X$) by the invertible (*invertible*) matrix $P$.

$$
X' = ‚Äã‚ÄãX \times P
$$

Inspection of how feature values ‚Äã‚Äãwill look after transformation. The *invertible* property is very important in this case, so make sure of $P$ that $P$ is *invertible*.
"""

personal_info_column_list = ['gender', 'age', 'income', 'family_members', 'insurance_benefits', 'insurance_benefits_received']
df_pn = df[personal_info_column_list]

df_masking = df_pn.to_numpy()

# Create a random matrix ùëÉ

rng = np.random.default_rng(seed=50)
P = rng.random(size=(df_masking.shape[1], df_masking.shape[1]))

# Checking whether the matrix ùëÉ is invertible

P_det = np.linalg.det(P)
print(P_det)

df_masking = df_masking @ P
df_masking = pd.DataFrame(df_masking)
df_masking.columns = (['gender', 'age', 'income', 'family_members', 'insurance_benefits', 'insurance_benefits_received'])
df_masking.head()

"""After the transformation is carried out, you can still determine the client's age and income because the masking result is not equal to 0."""

# Returns data that has been masked

P_inv = np.linalg.inv(P)

df_balik = df_masking @ P_inv
df_balik.columns = (['gender', 'age', 'income', 'family_members', 'insurance_benefits', 'insurance_benefits_received'])
df_balik.head()

# Masking check

pd.concat([df, df_masking, df_balik], axis=1, keys=['Asli', 'Masked', 'Returned']).head()

"""The dataset that has been masked and then returned to the original data shows changes in values ‚Äã‚Äãthat are not too significant. This is due to rounding in floating point decisions.

## **Linear Regression Test with Protected Data**

Now, let's prove that Linear Regression can work computationally with the selected blurring transformation.

Create a procedure or class that performs linear regression with data blurring. You can use linear regression available in scikit-learn or your own.

Run a linear regression on the original and masked data, comparing the predicted values ‚Äã‚Äãand RMSE, as well as the value of the $R^2$ metric. Is there a difference?

**Procedure**

- Create a square matrix $P$ from random numbers.
- Check whether the matrix is ‚Äã‚Äã*invertible*. If not, repeat from the first step until we get an invertible (*invertible*) matrix.
- <! type your comment here !>
- Use $XP$ as the new feature matrix
"""

df.head()

df_masking.head()

X = df_masking[['age', 'gender', 'income', 'family_members']].to_numpy()
y = df_masking['insurance_benefits'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

scaler = StandardScaler()
scaler.fit(X_train)

X_train = pd.DataFrame(scaler.transform(X_train), columns=feature_names)
X_train.head()

lr = MyLinearRegression()

lr.fit(X_train, y_train)
print(lr.weights)

y_test_pred = lr.predict(X_test)
eval_regressor(y_test, y_test_pred)

"""**Summary**

1. After masking, the RMSE value is 0.36 and R2 is 0.66, which indicates that the masked data does not produce a different value from the original data.

## **Conclusion**

1. Based on descriptive statistics, it can be seen that there are no problems with the dataset.
2. There are 153 rows that are duplicated and have been dropped duplicated to avoid redundant results.
3. Based on the results of analysis and exploratory data, it was concluded that age has a positive effect on receiving benefits.
4. The dummy model has a low level of accuracy and F1 score compared to kNN classification.
5. The level of accuracy and F1 score on the train and test datasets using the kNN approach has a relatively high value at more than 98%.
6. Obtained an RMSE score of 0.36.
7. Obtained an R2 score of 0.66.
8. After masking, the RMSE value is 0.36 and R2 is 0.66, which indicates that the masked data does not produce a different value from the original data.
"""

